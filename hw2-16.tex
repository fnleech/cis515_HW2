\documentclass[12pt]{article}
\usepackage{amsfonts,amssymb,amsmath}
%\documentstyle[12pt,amsfonts]{article}
%\documentstyle{article}

\setlength{\topmargin}{-.5in}
\setlength{\oddsidemargin}{0 in}
\setlength{\evensidemargin}{0 in}
\setlength{\textwidth}{6.5truein}
\setlength{\textheight}{8.5truein}
%\input ../basicmath/basicmathmac.tex
%
%\input ../lamacb.tex
\input ../mac.tex
\input ../mathmac.tex

\def\fseq#1#2{(#1_{#2})_{#2\geq 1}}
\def\fsseq#1#2#3{(#1_{#3(#2)})_{#2\geq 1}}
\def\qleq{\sqsubseteq}

%
\begin{document}
\begin{center}
\fbox{{\Large\bf Fall 2016 \hspace*{0.4cm} CIS 515}}\\
\vspace{1cm}
{\Large\bf Fundamentals of Linear Algebra and Optimization\\
Jean Gallier \\
\vspace{0.5cm}
Homework 2}\\[10pt]
September, 20 2016; Due October 11, 2016\\
Francine Leech, Chen Xiang, Reffat Manzur
\end{center}


\vspace {0.25cm}\noindent
{\bf Problem B1 (10 pts).} \\
Suppose $A = (a_{i,j})_{m \times n}$, $B = (b_{i,j})_{n \times p}$, C = $AB = (c_{i,j})_{m \times p}$.
It is easy to write $c_{ij} = \sum_{k=1}^{n} a_{ik} b_{kj},\; \forall i = 1,2,\cdots m.\; j = 1,2,\cdots p$ 
and then consider $(A^1B_1 + \cdots + A^nB_n)_{ij}$, we have $  (A^1B_1 + \cdots + A^nB_n)_{ij} = (a_{i1}b_{1j} + a_{i2}b_{2j} \cdots a_{in}b_{nj}) = \sum_{k=1}^{n} a_{ik} b_{kj}$. So $AB = A^1B_1 + \cdots + A^nB_n$.


\vspace {0.25cm}\noindent
{\bf Problem B2 (10 pts).} \\
Because $f$ is a linear map, thus we have 
\[
f(x + y) = f(x) + f(y)
\]
\[
f(\lambda x) = \lambda f(x)
\]
So write the inverse function $g = f^{-1}$ and $x_1,x_2 \in E$, we have 
\begin{align*}
\exists x \in E , \; x = g(f(x_1) + f(x_2)) &\Rightarrow 
f(x) = f(x_1) + f(x_2) = f(x_1 + x_2) \\
&\Rightarrow x = x_1 + x_2 \\
&\Rightarrow g(f(x)) = g(f(x_1 + x_2)) = g(f(x_1)) + g(f(x_2)) \\
\exists x^* \in E, \; x^* = g(f(\lambda x)) &\Rightarrow f(x^*) = f(\lambda x) \\
&\Rightarrow x^* = \lambda x \\
&\Rightarrow g(\lambda f(x)) = g(f(\lambda x)) = \lambda g(f(x))
\end{align*}



\vspace {0.25cm}\noindent
{\bf Problem B3 (10 pts).}
Given two vectors spaces $E$ and $F$, let $(u_i)_{i\in I}$
be any basis of $E$ and let $(v_i)_{i\in I}$ be any
family of vectors in $F$. Prove that the unique linear map
$\mapdef{f}{E}{F}$ such that $f(u_i) = v_i$ for all $i\in I$ 
is surjective iff  $(v_i)_{i\in I}$ spans $F$.

For $x\epsilon E$, it can be written as $x_{1}u_{1}+x_{2}u_{2}+\cdots+x_{n}u_{n}$as
$(u_{i})_{i\epsilon I}$is a basis of $E$ and $(u_{i})_{i\epsilon I}$spans
$E$ . Then, $f(x)=x_{1}f(u_{1})+x_{2}f(u_{2})+\cdots+x_{n}f(u_{n})$.
Since $f(u_{i})=v_{i}$, this can be rewritten as: $f(x)=x_{1}v_{1}+x_{2}v_{2}+\cdots+x_{n}v_{n}$.
If the linear map $f$ is surjective, then every element in $F$ has
a corresponding element in $E$ and $f(x)=x_{1}v_{1}+x_{2}v_{2}+\cdots+x_{n}v_{n}$
indicates that $(v_{i})_{i\epsilon I}$ must span $F$.
\vspace {0.25cm}\noindent
{\bf Problem B4 (10 pts).}
Let $\mapdef{f}{E}{F}$ be a linear map 
with $\mathrm{dim}(E) = n$ and $\mathrm{dim}(F)  = m$.
Prove that $f$ has rank $1$ iff $f$ is represented by an
$m\times n$ matrix of the form
\[
A = u\transpos{v}
\]
with $u$ a nonzero column vector of dimension $m$ and $v$ a 
nonzero column vector  of dimension $n$.
$dim(E)=n$ indicates that the basis of $E$ consists of $n$ vectors
and $dim(F)=m$ indicates the basis of $F$ consists of $m$ vectors.
From class notes, we know that $M(f)=\begin{pmatrix}a_{11} & \cdots & a_{1n}\\
\vdots & \ddots & \vdots\\
a_{m1} & \cdots & a_{mn}
\end{pmatrix}=A$, an $mxn$ matrix.

$u=\begin{pmatrix}u_{1}\\
u_{2}\\
u_{3}\\
\vdots\\
u_{m}
\end{pmatrix}$ and $v^{T}=\begin{pmatrix}v_{1} & v_{2} & v_{3} & \cdots & v_{n}\end{pmatrix}$
so $uv^{T}$ is an $mxn$ matrix of the form: $\begin{pmatrix}u_{1}v_{1} & u_{1}v_{2} & u_{1}v_{3} & \cdots & u_{1}v_{n}\\
u_{2}v_{1} & u_{2}v_{2} & u_{2}v_{3} & \cdots & u_{2}v_{n}\\
u_{3}v_{1} & u_{3}v_{2} & u_{3}v_{3} & \cdots & u_{3}v_{n}\\
\vdots & \vdots & \vdots & \cdots & \vdots\\
u_{m}v_{1} & u_{m}v_{2} & u_{m}v_{3} & \cdots & u_{m}v_{n}
\end{pmatrix}=v_{1}\begin{pmatrix}u_{1}\\
u_{2}\\
u_{3}\\
\vdots\\
u_{m}
\end{pmatrix}+v_{2}\begin{pmatrix}u_{1}\\
u_{2}\\
u_{3}\\
\vdots\\
u_{m}
\end{pmatrix}+\cdots v_{n}\begin{pmatrix}u_{1}\\
u_{2}\\
u_{3}\\
\vdots\\
u_{m}
\end{pmatrix}$. Since every column in the matrix of $f$ is a multiple of one column,
the rank is 1 for $f$ and the matrix is always of this form by definition
for an $mxn$ matrix.




\vspace {0.25cm}\noindent
{\bf Problem B5 (120 pts).} (Haar extravaganza)
Consider the matrix
\[
W_{3, 3} =
\begin{pmatrix}
1  &  0  &  0 & 0 & 1   &  0   & 0    & 0  \\
1  &  0  &  0 & 0 & -1 &  0   & 0    & 0  \\
0   &  1  &  0 & 0 &  0  & 1   & 0    & 0  \\
0   &  1  &  0 & 0 &  0  & -1 & 0    & 0  \\
0   &  0  &  1 & 0 &  0  &  0  & 1    & 0  \\
0   &  0  &  1 & 0 &  0  &  0  & -1  & 0  \\
0   &  0  &  0 & 1 &  0  &  0  & 0    & 1  \\
0   &  0  &  0 & 1 &  0  &  0  & 0    & -1  \\
\end{pmatrix}
\]

\medskip
(1)

\[
W_{3, 3} c =
\begin{pmatrix}
1  &  0  &  0 & 0 & 1   &  0   & 0    & 0  \\
1  &  0  &  0 & 0 & -1 &  0   & 0    & 0  \\
0   &  1  &  0 & 0 &  0  & 1   & 0    & 0  \\
0   &  1  &  0 & 0 &  0  & -1 & 0    & 0  \\
0   &  0  &  1 & 0 &  0  &  0  & 1    & 0  \\
0   &  0  &  1 & 0 &  0  &  0  & -1  & 0  \\
0   &  0  &  0 & 1 &  0  &  0  & 0    & 1  \\
0   &  0  &  0 & 1 &  0  &  0  & 0    & -1  \\
\end{pmatrix}
\cdot
\begin{pmatrix}
c_1 & \\
c_2 & \\
c_3 & \\
c_4 & \\
c_5 & \\
c_6 & \\
c_7 & \\
c_8 \\
\end{pmatrix}
\]

\[
= 
\begin{pmatrix}
1 \cdot c_1 + 1 \cdot c_5 \\
1 \cdot c_1 + -1 \cdot c_5 \\
1 \cdot c_2 + 1 \cdot c_6 \\
1 \cdot c_2 + -1 \cdot c_6\\
1 \cdot c_3 + 1 \cdot c_7 \\
1 \cdot c_3 + - 1 \cdot c_7 \\
1 \cdot c_4 + 1 \cdot c_8 \\
1 \cdot c_4 + -1 \cdot c_8 \\
\end{pmatrix}
\\ 
= 
\begin{pmatrix}
c_1 + c_5 \\
c_1 - c_5 \\
c_2 + c_6 \\
c_2 - c_6\\
c_3 + c_7 \\
c_3 - c_7 \\
c_4 + c_8 \\
c_4 - c_8 \\
\end{pmatrix}
\]

\medskip
(2) \\
If the inverse of $W_{3, 3}$ is $(1/2) \transpos{W_{3, 3}}$, then the product of the two matrices is the identity matrix. 
\[
W_{3, 3} \cdot (1/2) \transpos{W_{3, 3}}=
\begin{pmatrix}
1  &  0  &  0 & 0 & 1   &  0   & 0    & 0  \\
1  &  0  &  0 & 0 & -1 &  0   & 0    & 0  \\
0   &  1  &  0 & 0 &  0  & 1   & 0    & 0  \\
0   &  1  &  0 & 0 &  0  & -1 & 0    & 0  \\
0   &  0  &  1 & 0 &  0  &  0  & 1    & 0  \\
0   &  0  &  1 & 0 &  0  &  0  & -1  & 0  \\
0   &  0  &  0 & 1 &  0  &  0  & 0    & 1  \\
0   &  0  &  0 & 1 &  0  &  0  & 0    & -1  \\
\end{pmatrix}
\cdot
\begin{pmatrix}
0.5 & 0.5  & 0   & 0    & 0    & 0     & 0    & 0    \\ 
0   & 0    & 0.5 & 0.5  & 0    & 0     & 0    & 0    \\ 
0   & 0    & 0   & 0    & 0.5  & 0.5   & 0    & 0     \\
0   & 0    & 0   & 0    & 0    & 0     & 0.5  & 0.5   \\
0.5 & -0.5 & 0   & 0    & 0    & 0     & 0    & 0     \\
0   & 0    & 0.5 & -0.5 & 0    & 0     & 0    & 0     \\
0   & 0    & 0   & 0    & 0.5  & -0.5  & 0    & 0     \\
0   & 0    & 0   & 0    & 0    & 0     & 0.5  & -0.5  \\
\end{pmatrix}
\] 

\[
= 
\begin{pmatrix}
0.5 + 0.5  & 0.5 + -0.5 & 0          & 0          & 0          & 0          & 0          & 0          \\
0.5 + -0.5 & 0.5 --0.5  & 0          & 0          & 0          & 0          & 0          & 0          \\
0          & 0          & 0.5 + 0.5  & 0.5 +-0.5  & 0          & 0          &  0          & 0          \\
0          & 0          & 0.5 +-0.5  & 0.5 --0.5  & 0          & 0          & 0          & 0          \\
0          & 0          & 0          & 0          & 0.5 + 0.5  & 0.5 +-0.5  & 0          & 0          \\
0          & 0          & 0          & 0          & 0.5 +-0.5  & 0.5 --0.5  & 0          & 0          \\
0          & 0          & 0          & 0          & 0          & 0          & 0.5 + 0.5  & 0.5 +-0.5  \\
0          & 0          & 0          & 0          & 0          & 0             & 0.5 +-0.5  &  0.5 --0.5\\ 
\end{pmatrix}
\] 

\[
=
\begin{pmatrix}
1  & 0 & 0          & 0          & 0          & 0          & 0          & 0          \\
0 & 1  & 0          & 0          & 0          & 0          & 0          & 0          \\
0          & 0          & 1  & 0  & 0          & 0          &  0          & 0          \\
0          & 0          & 0  & 1 & 0          & 0          & 0          & 0          \\
0          & 0          & 0          & 0          & 1  & 0  & 0          & 0          \\
0          & 0          & 0          & 0          & 0  & 1  & 0          & 0          \\
0          & 0          & 0          & 0          & 0          & 0          & 1  & 0  \\
0          & 0          & 0          & 0          & 0          & 0             & 0  &  1\\ 
\end{pmatrix}
\] 
We have $W_{3, 3} = (\alpha_1, \alpha_2, \cdots, \alpha_8)$, then write $\alpha_i^T\alpha_j, \forall i,j = 1,2,\cdots8 \; i \neq j$ there are two conditions: \\
1. $\alpha_i$ and $\alpha_j$ have elements on the same positions. \\ 
2. $\alpha_i$ and $\alpha_j$ have elements on different postions. \\
For the first condition, we have $\alpha_i^T\alpha_j = 1-1=0$ and for the second condition, we have $\alpha_i^T\alpha_j = 0$. Also, $\alpha_i^T\alpha_i = 1 + 1 = 2$, so we can prove that the columns are orthogonal. It
is the same to prove the rows are orthogonal.


\medskip
(3)
Let $W_{3, 2}$ and $W_{3, 1}$ be the following matrices:
\[
W_{3, 2} =
\begin{pmatrix}
1  &  0  & 1    &  0   & 0    & 0  &  0  &  0  \\
1  &  0  &  -1 &  0   & 0    & 0  &  0  &  0 \\
0   &  1  &  0  &  1   & 0    & 0  &  0  &  0 \\
0   &  1  &  0  &  -1 & 0    & 0  &  0  &  0 \\
0   &  0  &  0 & 0 &  1  &  0  & 0    & 0  \\
0   &  0  &  0 & 0 &  0  &  1  &  0   & 0  \\
0   &  0  &  0 & 0 &  0  &  0  &  1   & 0  \\
0   &  0  &  0 & 0 &  0  &  0  & 0    & 1  \\
\end{pmatrix},
\quad
W_{3, 1} =
\begin{pmatrix}
1  &  1   & 0    &  0   & 0    & 0  &  0  &  0  \\
1  & -1  &  0   &  0   & 0    & 0  &  0  &  0 \\
0   &  0  &  1   &   0   & 0    & 0  &  0  &  0 \\
0   &  0   &  0  &   1 & 0    & 0  &  0  &  0 \\
0   &  0  &  0 & 0 &  1  &  0  & 0    & 0  \\
0   &  0  &  0 & 0 &  0  &  1  &  0   & 0  \\
0   &  0  &  0 & 0 &  0  &  0  &  1   & 0  \\
0   &  0  &  0 & 0 &  0  &  0  & 0    & 1  \\
\end{pmatrix}.
\]
Show that given any vector $c = (c_1, c_2, c_3, c_4, c_5, 
c_6,c_7, c_8)$, the result $W_{3, 2} c$ of applying $W_{3,2}$ to $c$ is 
\[
W_{3, 2} c =
(c_1 + c_3, c_1- c_3, c_2 + c_4, c_2 - c_4, c_5, c_6, c_7, c_8),
\]
the second step in reconstructing a vector  from its Haar coefficients, 
and the result $W_{3, 1} c$ of applying $W_{3, 1}$ to $c$ is 
\[
W_{3, 1} c =
(c_1 + c_2, c_1- c_2, c_3,  c_4, c_5, c_6, c_7, c_8),
\]
the first step in reconstructing a vector  from its Haar coefficients. 

\medskip
Conclude that
\[
W_{3, 3} W_{3, 2}W_{3, 1} = W_3,
\]
the Haar matrix 
\[
W_3 = 
\begin{pmatrix}
1  &  1   &  1  &  0   &  1  &  0  &  0  &  0  \\  
1  &  1   &  1  &  0   & -1 &  0  &  0  &  0 \\
1  &  1   & -1 &  0   &  0  &  1  &  0  &  0 \\
1  &  1   & -1 &  0   &  0  & -1 &  0  &  0 \\
1  & -1  &  0  &  1   &  0  &  0  &  1  &  0 \\
1  & -1  &  0  &  1   &  0  &  0  & -1 &  0 \\
1  & -1  &  0  & -1  &  0  &  0  &  0  &  1 \\
1  & -1  &  0  & -1  &  0  &  0  &  0  & -1
\end{pmatrix}.
\]

\hint
First, check that
\[
W_{3, 2}W_{3, 1} = 
\begin{pmatrix}
W_2 & 0_{4, 4} \\
0_{4, 4}         & I_4
\end{pmatrix},
\]
where
\[
W_2 = 
\begin{pmatrix}
1  &  1   &   1   &  0 \\
1  &  1   &  -1  &  0 \\
1  & -1  &   0   &  1 \\
1  & -1  &   0   & -1
\end{pmatrix}.
\]

\medskip
(4) 
Prove that the columns and the rows of $W_{3, 2}$ and $W_{3, 1}$
are orthogonal. Deduce from this that the columns of
$W_3$  are orthogonal, and the rows of $W_3^{-1}$ are orthogonal.  
Are the rows  of $W_3$ orthogonal? 
Are the columns  of $W_3^{-1}$ orthogonal? 
Find  the inverse of $W_{3, 2}$ and the inverse of $W_{3, 1}$.

\medskip
(5)
For any $n\geq 2$, the $2^n \times 2^n$ matrix $W_{n, n}$ is obtained form the
two rows
\begin{align*}
& \underbrace{1, 0, \ldots, 0}_{2^{n - 1}}, \underbrace{1, 0, \ldots,  0}_{2^{n - 1}} \\
& \underbrace{1, 0, \ldots, 0}_{2^{n - 1}}, \underbrace{-1, 0, \ldots,  0}_{2^{n - 1}} 
\end{align*}
by shifting them $2^{n - 1} - 1$ times over to the right by inserting a zero
on the left each time.

\medskip
Given any vector $c = (c_1, c_2, \ldots, c_{2^n})$, show that $W_{n, n} c$
is the result of the last step in  the
process of reconstructing a vector from its Haar coefficients $c$.
Prove that $W_{n, n}^{-1} = (1/2)\transpos{W_{n, n}}$, and that the
columns and the rows
of $W_{n, n}$ are orthogonal.


\medskip
{\bf Extra credit (30 pts.)}

\medskip
Given a $m\times n$ matrix $A = (a_{i j})$ and a $p\times q$ matrix
$B = (b_{i j})$, the {\it Kronecker product\/} (or {\it tensor
  product\/}) $A\tensor B$ of $A$ and $B$ is the $mp\times nq$ matrix
\[
A\tensor B =
\begin{pmatrix}
a_{1 1} B & a_{1 2} B & \cdots & a_{1 n} B \\
a_{2 1} B & a_{2 2} B & \cdots & a_{2 n} B \\
\vdots  & \vdots & \ddots & \vdots \\
a_{m 1} B & a_{m 2} B & \cdots & a_{m n} B 
\end{pmatrix} .
\]
It can be shown (and you may use these facts without proof) that
$\tensor$ is associative and that
\begin{align*}
(A\tensor B)(C\tensor D) & = AC \tensor BD \\
\transpos{(A\tensor B)} & = \transpos{A} \tensor \transpos{B}, 
\end{align*}
whenever $AC$ and $BD$ are well defined.

\medskip
Check that
\[
W_{n, n} =
\begin{pmatrix}
I_{2^{n-1}} \tensor 
\begin{pmatrix}
1 \\
1
\end{pmatrix}
& 
I_{2^{n-1}} \tensor 
\begin{pmatrix}
1 \\
-1
\end{pmatrix}
\end{pmatrix} ,
\]
and that
\[
W_{n} =
\begin{pmatrix}
W_{n-1} \tensor 
\begin{pmatrix}
1 \\
1
\end{pmatrix}
& 
I_{2^{n-1}} \tensor 
\begin{pmatrix}
1 \\
-1
\end{pmatrix}
\end{pmatrix} .
\]


\medskip
Use the above to reprove that
\[
W_{n, n}\transpos{W_{n, n}} = 2I_{2^n}.
\]
Let
\[
B_1 =
2
\begin{pmatrix}
1 & 0 \\
0 & 1
\end{pmatrix}
= 
\begin{pmatrix}
2 & 0 \\
0 & 2
\end{pmatrix}
\]
and for $n \geq 1$,
\[
B_{n+1} =
2
\begin{pmatrix}
B_n & 0 \\
0 & I_{2^n}
\end{pmatrix}.
\]
Prove that
\[
\transpos{W_n} W_n = B_n, \quad\hbox{for all $n \geq 1$}.
\]


We can find \[
\begin{pmatrix}
I_{2^{n-1}} \tensor 
\begin{pmatrix}
1 \\
1
\end{pmatrix}
& 
I_{2^{n-1}} \tensor 
\begin{pmatrix}
1 \\
-1
\end{pmatrix}
\end{pmatrix} \in M_{2^n,2^n}
\] 
and it is easy to get 
\[
I_{2^{n-1}} \tensor 
\begin{pmatrix}
1 \\
1
\end{pmatrix}
=
\begin{pmatrix}
1 & 0 & \cdots & 0 \\
1 & 0 & \cdots & 0 \\
0 & 1 & \cdots & \vdots \\
0 & 1 & \cdots & \vdots \\
\vdots  & \vdots & \ddots & \vdots \\
0 & 0 & \cdots &1 \\
0 & 0 & \cdots &1 \\
\end{pmatrix} 
\in M_{2^n, 2^{n-1}},
\]
\[
I_{2^{n-1}} \tensor 
\begin{pmatrix}
1 \\
-1
\end{pmatrix}
=
\begin{pmatrix}
1 & 0 & \cdots & 0 \\
-1 & 0 & \cdots & 0 \\
0 & 1 & \cdots & \vdots \\
0 & -1 & \cdots & \vdots \\
\vdots  & \vdots & \ddots & \vdots \\
0 & 0 & \cdots &1 \\
0 & 0 & \cdots &-1 \\
\end{pmatrix} 
\in M_{2^n, 2^{n-1}},
\]
so 
\[
\begin{pmatrix}
I_{2^{n-1}} \tensor 
\begin{pmatrix}
1 \\
1
\end{pmatrix}
&
I_{2^{n-1}} \tensor 
\begin{pmatrix}
1 \\
-1
\end{pmatrix}
\end{pmatrix}
=
\begin{pmatrix}
1 & 0 & \cdots & \cdots  & 1  & 0 & 0 \\
1 & 0 & \cdots & \cdots  & -1 & 0 & 0 \\
0 & 1 & \cdots & \cdots  & 0  & 1 & \vdots \\
0 & 1 & \cdots & \cdots  & 0  & -1 & \vdots \\
\vdots  & \vdots & \ddots & \vdots & \vdots \\
0 & 0 & \cdots &1 &0  & \cdots & 1 \\
0 & 0 & \cdots &1 &0  & \cdots & -1 
\end{pmatrix} 
= W_{n,n}.
\]
\begin{align*}
W_{n, n} \transpos{W_{n, n}} &= 
\begin{pmatrix}
I_{2^{n-1}} \tensor 
\begin{pmatrix}
1 \\
1
\end{pmatrix}
& 
I_{2^{n-1}} \tensor 
\begin{pmatrix}
1 \\
-1
\end{pmatrix}
\end{pmatrix}
\transpos{
\begin{pmatrix}
I_{2^{n-1}} \tensor 
\begin{pmatrix}
1 \\
1
\end{pmatrix}
& 
I_{2^{n-1}} \tensor 
\begin{pmatrix}
1 \\
-1
\end{pmatrix}
\end{pmatrix}} \\
&=
I_{2^{n-1}} \tensor 
\begin{pmatrix}
1 \\
1
\end{pmatrix}
\transpos{[
I_{2^{n-1}} \tensor 
\begin{pmatrix}
1 \\
1
\end{pmatrix}
]} + 
I_{2^{n-1}} \tensor 
\begin{pmatrix}
1 \\
-1
\end{pmatrix}
\transpos{[
I_{2^{n-1}} \tensor 
\begin{pmatrix}
1 \\
-1
\end{pmatrix}]
} \\
\end{align*}
according to the facts above, we have
\begin{align*}
W_{n, n} \transpos{W_{n, n}} &= 
[I_{2^{n-1}} \tensor 
\begin{pmatrix}
1 \\
1
\end{pmatrix}]
[I_{2^{n-1}} \tensor 
\transpos{\begin{pmatrix}
1 \\
1
\end{pmatrix}
}] + 
[I_{2^{n-1}} \tensor 
\begin{pmatrix}
1 \\
-1
\end{pmatrix}]
[I_{2^{n-1}} \tensor 
\transpos{
\begin{pmatrix}
1 \\
-1
\end{pmatrix}}] \\
&=
I_{2^{n-1}} \tensor 
\begin{pmatrix}
1 &1 \\
1 &1 
\end{pmatrix} +
I_{2^{n-1}} \tensor 
\begin{pmatrix}
1 &-1 \\
-1 &1 
\end{pmatrix} \\
&= 
I_{2^{n-1}} \tensor 
\begin{pmatrix}
2 &0 \\
0 &2 
\end{pmatrix} = 
2I_{2^n} 
\end{align*}





\medskip
(6)
The matrix $W_{n, i}$ is obtained from the matrix $W_{i, i}$ 
($1 \leq i \leq n - 1$) as follows:
\[
W_{n, i} = 
\begin{pmatrix}
 W_{i, i} & 0_{2^{i}, 2^{n} - 2^{i}} \\
0_{2^{n}- 2^{i}, 2^i} & I_{2^{n} - 2^{i}}
\end{pmatrix}.
\]
It consists of four blocks,
where  $0_{2^{i}, 2^{n} - 2^{i}}$ and $0_{2^{n} - 2^{i}, 2^i}$
are matrices of zeros and $I_{2^{n} - 2^{i}}$ is the identity matrix of
dimension $2^{n} - 2^i$.

\medskip
Explain what $W_{n, i}$ does to $c$ and prove that
\[
W_{n, n} W_{n, n - 1} \cdots W_{n, 1} = W_n,
\]
where $W_n$ is the Haar matrix of dimension $2^n$.

\medskip
\hint
Use induction on $k$,  with the induction hypothesis
\[
W_{n, k} W_{n, k - 1}\cdots W_{n, 1} = 
\begin{pmatrix}
 W_{k} & 0_{2^{k}, 2^{n} - 2^{k}} \\
0_{2^{n}- 2^{k}, 2^k} &  I_{2^{n} - 2^{k}}
\end{pmatrix}.
\]


\medskip
Prove that the columns and rows of $W_{n, k}$ are orthogonal, and use
this to prove that the columns of $W_n$ and the rows of
$W_n^{-1}$ are orthogonal. 
Are the rows of  $W_n$ orthogonal?
Are the columns of  $W_n^{-1}$ orthogonal?
Prove that
\[
W_{n, k}^{-1} = 
\begin{pmatrix}
 \frac{1}{2}\transpos{W_{k, k}} & 0_{2^{k}, 2^{n} - 2^{k}} \\
0_{2^{n}- 2^{k}, 2^k} &  I_{2^{n} - 2^{k}}
\end{pmatrix}.
\]


\vspace {0.25cm}\noindent
{\bf Problem B6 (20 pts).}
Prove that 
for every vector space $E$, if $\mapdef{f}{E}{E}$ is an idempotent
linear map, i.e., $f\circ f = f$, then we have a direct sum
\[
E = \Ker{f} \oplus \Im{f},
\]
so that $f$ is the projection onto its image $\Im{f}$.


\vspace {0.25cm}\noindent
{\bf Problem B7 (20 pts).}
Let $U_1, \ldots, U_p$ be any  $p \geq 2$  subspaces of some vector
space $E$ and recall that the linear map
\[
\mapdef{a}{U_1\times \cdots \times U_p}{E}
\]
is given by
\[
a(u_1, \ldots, u_p) = u_1 + \cdots + u_p,
\]
with $u_i \in U_i$ for $i = 1, \ldots, p$.

\medskip
(1)
If we let $Z_i \subseteq U_1\times \cdots \times U_p$ be given by
\[
Z_i = \left.\bigg\{\Big(u_1, \ldots, u_{i - 1}, -\sum_{j = 1, j \not= i}^p u_j, u_{i + 1}, 
\ldots, u_p\Big) \>\right|\> \sum_{j = 1, j \not= i}^p u_j  \in  
U_i \cap \bigg(\sum_{j = 1, j \not= i}^p U_j \bigg) 
\bigg\},
\]
for $i = 1, \ldots, p$, then prove that
\[
\Ker{a} = Z_1 = \cdots =   Z_p.
\]
In general, for any given $i$, the condition
$U_i \cap \bigg(\sum_{j = 1, j \not= i}^p U_j \bigg) =
(0)$ does not necessarily imply that $Z_i = (0)$.
Thus, let 
\[
Z = \left.\bigg\{\Big(u_1, \ldots, u_{i - 1}, u_i, u_{i + 1}, 
\ldots, u_p\Big) \>\right|\> u_i =  -\sum_{j = 1, j \not= i}^p u_j, \>
u_i   \in  
U_i \cap \bigg(\sum_{j = 1, j \not= i}^p U_j \bigg), \> 1\leq i \leq p 
\bigg\}.
\]
Since $\Ker{a} = Z_1 = \cdots =  Z_p$, we have $Z = \Ker a$.
Prove that if
\[
U_i \cap \bigg(\sum_{j = 1, j \not= i}^p U_j \bigg) = (0)
\quad 1 \leq i \leq p,
\]
then $Z = \Ker a = (0)$.

\medskip
(2)
Prove that $U_1 + \cdots + U_p$ is a direct sum iff
\[
U_i \cap \bigg(\sum_{j = 1, j \not= i}^p U_j \bigg) = (0)
\quad 1 \leq i \leq p.
\]


\medskip\noindent
(3)
{\bf Extra credit (40 pts)\/}.
Assume that $E$ is finite-dimensional, and
let $\mapdef{f_i}{E}{E}$ be any 
$p\geq 2$ linear maps such that
\[
f_1 + \cdots + f_p  = \id_E.
\]
Prove that the following properties are equivalent:
\begin{enumerate}
\item[(1)]
$f_i^2 = f_i$, $1\leq i \leq p$.
\item[(2)]
$f_j \circ f_i =  0$, for all $i \not= j$, $1\leq i, j \leq p$.
\end{enumerate}

(1) $\Rightarrow$ (2) 

We multiply $f_i$ on each side of the equation, then get 
\[
f_i^2 + \sum_{j \neq i} f_j \circ f_i = f_i
\]
\[
 \sum_{j \neq i} f_j \circ f_i  = 0
\] \\

Because $E$ is finite-dimensional, then for all $y \in E$ we can write $y = \sum \lambda_i x_i$, where $(x_i)$ is the base. Then for all $y \in E$, we have $ \sum_{j \neq i} f_j \circ f_i (y) = 0$, suppose there is a $k$ which makes $ f_k \circ f_i \neq 0 $ then $ker( f_k \circ f_i ) = E$, thus $ f_k \circ f_i  = 0$, which is a contradiction. \\

(2) $\Rightarrow$ (1)

We multiply $f_i, \; \forall i = 1,2,\cdots, p$ on each side of the equation, then get 
\[
f_i^2 + \sum_{j \neq i} f_j \circ f_i = f_i
\]
\[
 f_i^2 = f_i
\]


\vspace{0.5cm}\noindent
{\bf TOTAL: 200  + 70 points.}

\end{document}
